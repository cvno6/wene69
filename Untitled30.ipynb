{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YkDDcHrxr-4",
        "outputId": "f978f0e2-1828-47d5-e1e0-07a87616a604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_probability/python/layers/util.py:99: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  loc = add_variable_fn(\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_probability/python/layers/util.py:109: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use the `layer.add_weight()` method instead.\n",
            "  untransformed_scale = add_variable_fn(\n",
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836ms/step - accuracy: 0.3607 - loss: 1.0892 - val_accuracy: 0.3750 - val_loss: 1.0679\n",
            "Epoch 2/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 168ms/step - accuracy: 0.3346 - loss: 1.1065 - val_accuracy: 0.3333 - val_loss: 1.1005\n",
            "Epoch 3/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3203 - loss: 1.0995 - val_accuracy: 0.4583 - val_loss: 1.0662\n",
            "Epoch 4/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3086 - loss: 1.0911 - val_accuracy: 0.5000 - val_loss: 1.0598\n",
            "Epoch 5/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2604 - loss: 1.1035 - val_accuracy: 0.4167 - val_loss: 1.0498\n",
            "Epoch 6/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.3177 - loss: 1.0981 - val_accuracy: 0.6250 - val_loss: 1.0402\n",
            "Epoch 7/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.3307 - loss: 1.0917 - val_accuracy: 0.5833 - val_loss: 1.0380\n",
            "Epoch 8/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3763 - loss: 1.0904 - val_accuracy: 0.5000 - val_loss: 1.0722\n",
            "Epoch 9/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3047 - loss: 1.1142 - val_accuracy: 0.5417 - val_loss: 1.0615\n",
            "Epoch 10/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2565 - loss: 1.1020 - val_accuracy: 0.6250 - val_loss: 1.0237\n",
            "Epoch 11/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2982 - loss: 1.1270 - val_accuracy: 0.5000 - val_loss: 1.0584\n",
            "Epoch 12/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.2969 - loss: 1.0983 - val_accuracy: 0.5833 - val_loss: 1.0548\n",
            "Epoch 13/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3008 - loss: 1.1085 - val_accuracy: 0.5833 - val_loss: 1.0397\n",
            "Epoch 14/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3359 - loss: 1.1063 - val_accuracy: 0.4167 - val_loss: 1.0939\n",
            "Epoch 15/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2552 - loss: 1.1160 - val_accuracy: 0.4167 - val_loss: 1.0742\n",
            "Epoch 16/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2708 - loss: 1.1049 - val_accuracy: 0.4583 - val_loss: 1.0692\n",
            "Epoch 17/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3555 - loss: 1.0990 - val_accuracy: 0.5000 - val_loss: 1.0712\n",
            "Epoch 18/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2852 - loss: 1.1064 - val_accuracy: 0.6250 - val_loss: 1.0490\n",
            "Epoch 19/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2839 - loss: 1.1117 - val_accuracy: 0.3333 - val_loss: 1.0892\n",
            "Epoch 20/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3190 - loss: 1.0987 - val_accuracy: 0.5417 - val_loss: 1.0723\n",
            "Epoch 21/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3320 - loss: 1.1013 - val_accuracy: 0.5000 - val_loss: 1.0532\n",
            "Epoch 22/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2799 - loss: 1.1234 - val_accuracy: 0.4167 - val_loss: 1.0935\n",
            "Epoch 23/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2839 - loss: 1.1174 - val_accuracy: 0.3750 - val_loss: 1.0859\n",
            "Epoch 24/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2122 - loss: 1.1191 - val_accuracy: 0.4167 - val_loss: 1.0673\n",
            "Epoch 25/25\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3411 - loss: 1.1101 - val_accuracy: 0.5000 - val_loss: 1.0878\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step\n",
            "Accuracy: 0.3667\n",
            "Precision: 0.2917\n",
            "Recall: 0.3667\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Load and prepare the Iris dataset\n",
        "df = sns.load_dataset('iris')\n",
        "x = df.drop(columns=['species'])\n",
        "y = df['species']\n",
        "\n",
        "\n",
        "# Encode the labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "\n",
        "# Split the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define the model using tf.keras.Model\n",
        "class BayesianNN(Model):\n",
        "    def __init__(self):\n",
        "        super(BayesianNN, self).__init__()\n",
        "        # Define the DenseFlipout layers\n",
        "        self.dense1 = tfp.layers.DenseFlipout(64, activation='relu')\n",
        "        self.dense2 = tfp.layers.DenseFlipout(32, activation='relu')\n",
        "        self.dense3 = tfp.layers.DenseFlipout(3, activation='softmax')\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.dense3(x)\n",
        "\n",
        "\n",
        "# Create and compile the Bayesian Neural Network\n",
        "model = BayesianNN()\n",
        "model.build(input_shape=(None, x_train.shape[1]))  # Set input shape for the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n",
        "# Make predictions\n",
        "y_pred_prob = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n"
      ]
    }
  ]
}