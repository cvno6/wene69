{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAqh5W3ZscB8",
        "outputId": "ae33fde4-f1d8-4760-f629-7b735970d8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND Gate Predictions:\n",
            "[0 0] -> -0.27777777777777696\n",
            "[0 1] -> 0.25000000000000006\n",
            "[1 0] -> 0.27777777777777796\n",
            "[1 1] -> 0.8055555555555549\n",
            "\n",
            "NAND Gate Predictions:\n",
            "[0 0] -> 1.2777777777777768\n",
            "[0 1] -> 0.7499999999999999\n",
            "[1 0] -> 0.7222222222222218\n",
            "[1 1] -> 0.19444444444444486\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SinglePerceptronRegression:\n",
        "    def __init__(self, input_size):\n",
        "        self.input_size = input_size\n",
        "        self.weights = np.random.rand(input_size)\n",
        "        self.bias = np.random.rand()\n",
        "        self.learning_rate = 0.1\n",
        "\n",
        "    def activation(self, x):\n",
        "        return x\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        return self.activation(summation)\n",
        "\n",
        "    def train(self, training_inputs, labels, epochs):\n",
        "        for _ in range(epochs):\n",
        "            for inputs, label in zip(training_inputs, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                error = label - prediction\n",
        "                self.weights += self.learning_rate * error * inputs\n",
        "                self.bias += self.learning_rate * error\n",
        "\n",
        "\n",
        "# Define AND gate inputs and labels for regression\n",
        "and_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "and_labels = np.array([0, 0, 0, 1])\n",
        "\n",
        "# Define NAND gate inputs and labels for regression\n",
        "nand_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "nand_labels = np.array([1, 1, 1, 0])\n",
        "\n",
        "# Create perceptrons for AND and NAND gates regression\n",
        "and_perceptron = SinglePerceptronRegression(2)\n",
        "nand_perceptron = SinglePerceptronRegression(2)\n",
        "\n",
        "# Train perceptrons\n",
        "and_perceptron.train(and_inputs, and_labels, epochs=1000)\n",
        "nand_perceptron.train(nand_inputs, nand_labels, epochs=1000)\n",
        "\n",
        "# Test AND gate regression\n",
        "print(\"AND Gate Predictions:\")\n",
        "for inputs in and_inputs:\n",
        "    print(f\"{inputs} -> {and_perceptron.predict(inputs)}\")\n",
        "\n",
        "# Test NAND gate regression\n",
        "print(\"\\nNAND Gate Predictions:\")\n",
        "for inputs in nand_inputs:\n",
        "    print(f\"{inputs} -> {nand_perceptron.predict(inputs)}\")\n"
      ]
    }
  ]
}